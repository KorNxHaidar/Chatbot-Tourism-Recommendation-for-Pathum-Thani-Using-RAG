{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Korn\\Desktop\\dsi314\\Chatbot-Tourism-Recommendation-for-Pathum-Thani-Using-RAG\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import overload\n",
    "from collections import defaultdict\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores import VectorStore\n",
    "from openai import OpenAI\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korn\\Desktop\\dsi314\\Chatbot-Tourism-Recommendation-for-Pathum-Thani-Using-RAG\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(\"C:\\\\Users\\\\Korn\\\\Desktop\\\\dsi314\\\\Chatbot-Tourism-Recommendation-for-Pathum-Thani-Using-RAG\")\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restructure_json(input_path: str, main_key: str = \"name\"):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    updated_data = {main_key: data}\n",
    "\n",
    "    with open(input_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(updated_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "@overload\n",
    "def extract_data(path: str, main_key: str)->list[Document]:...\n",
    "\n",
    "@overload\n",
    "def extract_data(path: str)->list[Document]:...\n",
    "\n",
    "def extract_data(path: str, main_key:str=\"name\")->list[Document]:\n",
    "    documents: list[Document] = []\n",
    "    with open(path, \"r\", encoding='utf8') as json_file:\n",
    "        data:list[dict[str, str]] = json.load(json_file)[main_key]\n",
    "\n",
    "        for each_data in data:\n",
    "          page_content: str = \"\"\n",
    "          for k in each_data:\n",
    "              page_content = page_content + f\"\\n{k} {each_data[k]}\"\n",
    "          current_document = Document(\n",
    "              page_content=page_content,\n",
    "          )\n",
    "          documents.append(current_document)\n",
    "    return documents\n",
    "\n",
    "def format_reviews(input_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)[\"name\"]\n",
    "\n",
    "    grouped_data = defaultdict(lambda: {\n",
    "        \"description\": \"\",\n",
    "        \"main_category\": \"\",\n",
    "        \"rating_x\": 0,\n",
    "        \"review_texts\": [],\n",
    "        \"workday_timing\": \"\",\n",
    "        \"closed_on\": \"\",\n",
    "        \"address\": \"\",\n",
    "        \"website\": \"\",\n",
    "        \"phone\": \"\",\n",
    "        \"link\": \"\"\n",
    "    })\n",
    "\n",
    "    for entry in data:\n",
    "        place_name = entry[\"place_name\"]\n",
    "        grouped = grouped_data[place_name]\n",
    "        grouped[\"description\"] = entry[\"description\"]\n",
    "        grouped[\"main_category\"] = entry[\"main_category\"]\n",
    "        grouped[\"rating_x\"] = entry[\"rating_x\"]\n",
    "        grouped[\"review_texts\"].append(entry[\"review_text\"])\n",
    "        grouped[\"workday_timing\"] = entry[\"workday_timing\"]\n",
    "        grouped[\"closed_on\"] = entry[\"closed_on\"]\n",
    "        grouped[\"address\"] = entry[\"address\"]\n",
    "        grouped[\"website\"] = entry[\"website\"]\n",
    "        grouped[\"phone\"] = entry[\"phone\"]\n",
    "        grouped[\"link\"] = entry[\"link\"]\n",
    "\n",
    "        # รวม review_texts เป็นข้อความเดียว\n",
    "    for place_name, details in grouped_data.items():\n",
    "        details[\"review_texts\"] = \"\\n\\n\".join(details[\"review_texts\"])\n",
    "\n",
    "    formatted_data = [\n",
    "        {\"place_name\": place_name, **details}\n",
    "        for place_name, details in grouped_data.items()\n",
    "    ]\n",
    "\n",
    "    with open(input_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(formatted_data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs\n",
    "doc_paths = [\n",
    "    \"./data\\darft.pdf\",\n",
    "    \"./data\\draft2.pdf\",\n",
    "    \"./data\\All_merged_file.csv\",\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for doc_file in doc_paths:\n",
    "    file_path = Path(doc_file)\n",
    "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    try:\n",
    "        if str(file_path).endswith(\".pdf\"):\n",
    "            loader = PyMuPDFLoader(file_path=file_path)\n",
    "            data = loader.load_and_split()\n",
    "        elif str(file_path).endswith(\".csv\"):\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df[['place_name','description','total reviews','website','phone','main_category','rating score','review','workday_timing','closed_on','address','google map']]\n",
    "            df = df.drop_duplicates(subset=['place_name'])\n",
    "            max_length = 300\n",
    "            df = df[df['review'].str.len() <= max_length]\n",
    "            df.to_json(f'./data\\cleaned_{file_name}.json', force_ascii=False, orient='records')            \n",
    "            restructure_json(f'./data\\cleaned_{file_name}.json')\n",
    "            data = extract_data(f'./data\\cleaned_{file_name}.json')\n",
    "        else:\n",
    "            print('Upload a file successful')\n",
    "            sys.exit()\n",
    "\n",
    "        docs.extend(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading document {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1518, which is longer than the specified 1024\n"
     ]
    }
   ],
   "source": [
    "# Split docs\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=1024, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='place_name 3BRO’ COFFEE\n",
      "description ร้านกาแฟขนาดเล็ก อบอุ่นเหมือนบ้าน\n",
      "total reviews 11\n",
      "website https://www.facebook.com/profile.php?id=100070472935430\n",
      "phone 089 903 6727\n",
      "main_category ร้านกาแฟ\n",
      "rating score 5.0\n",
      "review รสชาติดี ราคาไม่แพง\n",
      "จอดรถในซอยได้แต่ต้องมองดีๆเพราะรถที่จอดปากทางบังทางเข้า\n",
      "workday_timing 8:30–16:00\n",
      "closed_on วันอาทิตย์\n",
      "address 109 ตำบล บ้านใหม่ อำเภอเมืองปทุมธานี ปทุมธานี 12000\n",
      "google map https://maps.app.goo.gl/yTN3ZFDKSkorPYfAA'\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(texts)):\n",
    "    cleaned_content = re.sub(r'[\\u202a-\\u202e]', '', texts[i].page_content)\n",
    "    texts[i] = Document(metadata=texts[i].metadata, page_content=cleaned_content)\n",
    "\n",
    "print(texts[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HuggingFaceEmbeddings\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing embeddings in the vector store\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store saved to ./vectorstore_directory\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./vectorstore_directory\"\n",
    "vectorstore.save_local(save_path)\n",
    "print(f\"Vector Store saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "load_path = \"./vectorstore_directory\"\n",
    "vectorstore = FAISS.load_local(load_path, embeddings, allow_dangerous_deserialization=True)\n",
    "print(\"Vector Store loaded successfully!\")\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "typhoon_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "    You are an intelligent assistant for question-answering tasks about Pathum Thani, Thailand.\n",
    "    Analyze the context and question carefully to provide an appropriate response.\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Scenario Detection:\n",
    "    1. If the question is about a Tourist attraction, Cafe, or Restaurant:\n",
    "    Response Format:\n",
    "    - Provide information for at least 3 places.\n",
    "    - For each place:\n",
    "        - Name of the attraction\n",
    "        - Description of the place (e.g., unique features, activities available)\n",
    "        - Opening and closing hours (if available)\n",
    "        - Additional information (e.g., transportation tips, entrance fees, or special advice)\n",
    "        - Rating Score (1-5 stars)\n",
    "        - Total Review\n",
    "        - Review\n",
    "        - Website (if available)\n",
    "        - Google map (if available)\n",
    "\n",
    "    2. For general conversational questions:\n",
    "    Respond naturally in Thai or English, addressing the specific query without a fixed format.\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Important Guidelines:\n",
    "    - Respond in Thai or English depending on the language of the question.\n",
    "    - Provide accurate and helpful information.\n",
    "    - If no information is available, respond with \"I don't know\" in the language of the question.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#typhoon_token = os.getenv(\"TYPHOON_API_KEY\")\n",
    "\n",
    "# Initialize the Typhoon client\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"TYPHOON_API_KEY\"),\n",
    "    base_url='https://api.opentyphoon.ai/v1'\n",
    ")\n",
    "\n",
    "# Define a function to generate a response using the LLM\n",
    "def generate_response(context, chat_history, question):\n",
    "    history = \"\\n\".join([f\"User: {entry['user']}\\nAssistant: {entry['assistant']}\" for entry in chat_history])\n",
    "    prompt = f\"{typhoon_prompt}\\n\\n{history}\\n\\nContext: {context}\\n\\nUser: {question}\\nAssistant:\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"typhoon-v1.5x-70b-instruct\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=2048,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "# Main function to handle user query\n",
    "def answer_question(user_question, chat_history):\n",
    "    retrieved_contexts = retriever.get_relevant_documents(user_question)\n",
    "    context = \"\\n\".join([doc.page_content for doc in retrieved_contexts])\n",
    "    response = generate_response(context=context, chat_history=chat_history, question=user_question)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korn\\AppData\\Local\\Temp\\ipykernel_8492\\88828299.py:22: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  retrieved_contexts = retriever.get_relevant_documents(user_question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: จังหวัดปทุมธานีมีวัดที่น่าสนใจหลายแห่ง ที่จะแนะนำให้คุณทราบดังนี้\n",
      "\n",
      "1. วัดไผ่ล้อม: ตั้งอยู่ไม่ไกลจากตัวเมืองปทุมธานี มีสถาปัตยกรรมที่ผสมผสานระหว่างศิลปะแบบอยุธยาตอนปลายและศิลปะแบบจีน มีพระประธานในอุโบสถเป็นพระพุทธรูปปางมารวิชัย และมีเจดีย์ 5 องค์ที่ได้รับอิทธิพลจากศิลปะแบบจีน\n",
      "\n",
      "2. วัดมูลจินดาราม: ตั้งอยู่ที่ตำบลบึงยี่โถ อำเภอธัญบุรี สร้างขึ้นเมื่อปี พ.ศ. 2439 โดยพระปฏิบัติราชประสงค์ (นามมูลเลอร์ ชาวเยอรมัน) และนางจีน ผู้เป็นภรรยา ได้รับพระราชทานวิสุงคามสีมาเมื่อปี พ.ศ. 2442\n",
      "\n",
      "3. วัดสระบัว: ตั้งอยู่ในตำบลบึงสนั่น อำเภอธัญบุรี จังหวัดปทุมธานี สร้างขึ้นเมื่อปี พ.ศ. 2425 โดยพระอธิการนก นายสมหวัง และนางจู ได้รับพระราชทานวิสุงคามสีมาเมื่อปี พ.ศ. 2460\n",
      "\n",
      "4. วัดบางหลวง: สร้างในสมัยกรุงศรีอยุธยา มีพระประธานในอุโบสถเป็นพระพุทธรูปปางมารวิชัย มีหลวงพ่อเพชรเป็นพระพุทธรูปสมัยเชียงแสน มีพุทธลักษณะพิเศษ คือ พระหัตถ์ซ้ายบิดไปมาได้\n",
      "\n",
      "5. วัดหงส์ปทุมาวาส: ตั้งอยู่ริมแม่น้ำเจ้าพระยา ในตำบลบางปรอก อำเภอเมืองปทุมธานี จังหวัดปทุมธานี เป็นวัดที่ได้รับรางวัลชนะเลิศโครงการอนุรักษ์พันธุ์ปลาหน้าวัด มีพันธุ์ปลาต่าง ๆ มากมาย\n",
      "\n",
      "6. วัดเสด็จ: ตั้งอยู่ที่ หมู่ 5 บ้านคลองกระแชง ตำบลสวนพริกไทย อำเภอเมืองปทุมธานี จังหวัดปทุมธานี เป็นวัดราษฎร์และโบราณสถานในจังหวัดปทุมธานี\n",
      "\n",
      "7. วัดโบสถ์: ตั้งอยู่ริมแม่น้ำเจ้าพระยา ในหมู่ที่ 1 บ้านท้ายดง ตำบลบางกระบือ อำเภอสามโคก จังหวัดปทุมธานี มีพระพุทธรูปศักดิ์สิทธิ์ที่เรียกกันว่า “หลวงพ่อเหลือ” ซึ่งถือเป็นพระคู่บ้านคู่เมืองของปทุมธานี\n",
      "Exiting chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Main loop with chat history\n",
    "chat_history = []\n",
    "query = None\n",
    "\n",
    "while True:\n",
    "    if not query:\n",
    "        query = input(\"Please ask your question (or type 'quit' to exit): \")\n",
    "    if query.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"Exiting chat. Goodbye!\")\n",
    "        break\n",
    "    answer = answer_question(query, chat_history)\n",
    "    chat_history.append({\"user\": query, \"assistant\": answer})\n",
    "    print(\"\\nAssistant:\", answer)\n",
    "    query = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
